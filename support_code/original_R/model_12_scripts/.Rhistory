mcnemar.test(mat,continuity=FALSE)
mcnemar.test(mat,correct = FALSE)
mat<-rbind(c(9,16),c(37,82))
mcnemar.test(mat,correct = FALSE)
chisq.test(mat,correct = FALSE)
chisq.test(rbind(c(46,25),c(98,119)),correct = FALSE)
install.packages("faraway")
data(orings)
orings
library(faraway)
orings
data
plot(orings)
qplot(orings)
library(ggplot2)
str(orings)
g<-ggplot(aes(x=temp,y=damage),data=orings) + geom_point()
g
?orings
g<-ggplot(aes(x=temp,y=damage),data=orings) + geom_point() +
g <- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Num Damage incidents out of 6 possible")
g
g<- ggplot(aes(x=temp,y=damage),data=orings) + geom_point()
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Num Damage incidents out of 6 possible") + scale_x_continuous(limits=c(min(orings$temp),max(orings$temp)))
g
g<- g + ylab("Num Damage incidents out of 6 possible") + scale_x_continuous(limits=c(min(orings$temp)-10,max(orings$temp)))
g
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point()
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event") + scale_x_continuous(limits=c(min(orings$temp)-10,max(orings$temp)))
g
fit <- lm(damage~temp,data=orings)
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point() + geom_line(aes(x=orings$temp,y=fit$fitted.values))
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event") + scale_x_continuous(limits=c(min(orings$temp)-10,max(orings$temp)))
g
fit$coefficients[1]
fit$coefficients[2]
g <- g + geom_text(data=NULL, x = 70, y = 1.5, label=paste0("$\Beta =$",fit$coefficients[2])
g <- g + geom_text(data=NULL, x = 70, y = 1.5, label=paste0("$\Beta =$",fit$coefficients[2]))
g <- g + geom_text(data=NULL, x = 70, y = 1.5, label=paste0(expression(beta),fit$coefficients[2]))
g
g <- g + geom_text(data=NULL, x = 70, y = 1.5, label=paste0(expression(beta =),fit$coefficients[2]))
g
g <- g + geom_text(data=NULL, x = 70, y = 1.5, label=paste0(expression(beta =),round(fit$coefficients[2]),2))
g
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point() + geom_line(aes(x=orings$temp,y=fit$fitted.values))
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event") + scale_x_continuous(limits=c(min(orings$temp)-10,max(orings$temp)))
g <- g + geom_text(data=NULL, x = 70, y = 1.5, label=paste0(expression(beta =),round(fit$coefficients[2]),2))
g
fit <- lm(damage~temp,data=orings)
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point() + geom_line(aes(x=orings$temp,y=fit$fitted.values))
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event") + scale_x_continuous(limits=c(min(orings$temp)-10,max(orings$temp)))
g <- g + geom_text(data=NULL, x = 70, y = 1.5, label=paste0(expression(beta),round(fit$coefficients[2]),2))
g
fit <- lm(damage~temp,data=orings)
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point() + geom_line(aes(x=orings$temp,y=fit$fitted.values))
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event") + scale_x_continuous(limits=c(min(orings$temp)-10,max(orings$temp)))
g <- g + geom_text(data=NULL, x = 70, y = 1.5, label=paste0("slope = ",round(fit$coefficients[2]),3))
g
fit$coefficients
fit <- lm(damage~temp,data=orings)
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point() + geom_line(aes(x=orings$temp,y=fit$fitted.values))
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event") + scale_x_continuous(limits=c(min(orings$temp)-10,max(orings$temp)))
g <- g + geom_text(data=NULL, x = 70, y = 1.5, label=paste0("slope = ",fit$coefficients[2]))
g
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point() + geom_line(aes(x=orings$temp,y=fit$fitted.values))
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event") + scale_x_continuous(limits=c(min(orings$temp)-10,max(orings$temp)))
g <- g + geom_text(data=NULL, x = 70, y = 1.5, label=paste0("slope = ",round(fit$coefficients[2],3)))
g
summary(fit)
cmod <- glm(cbind(damage,6-damage)~temp,family=binomial,data=orings)
summary(cmod) #output omitted
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point() + stat_smooth(aes(x=orings$temp,y=cmod$fitted.values))
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event") + scale_x_continuous(limits=c(min(orings$temp)-10,max(orings$temp)))
g
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point() + stat_smooth(aes(x=25,y=cmod$fitted.values))
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event")
g
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point() + stat_smooth(aes(x=newdata,y=predict.glm(cmod,newdata )))
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event")
g
newdata<-seq(from=25,to=85,by=1)
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point() + stat_smooth(aes(x=newdata,y=predict.glm(cmod,newdata )))
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event")
g
g<- ggplot(aes(x=temp,y=damage/6),data=orings) + geom_point() + geom_line(aes(x=newdata,y=predict.glm(cmod,newdata )))
g<- g + ggtitle("Damage Incidents vs. Temperature") + xlab("Temperature (F)")
g<- g + ylab("Probability of Damage event")
g
summary(cmod) #output omitted
exp(cmod$coefficients[2])
library(MASS)
predict(cmod,newdata=31)
predict?
}
?predict
predict.glm(cmod,newdata=31)
predict.glm(cmod,newdata=vector(31))
x<-31
x
predict(cmod,x)
confint(cmod)
apply(confint(cmod),exp)
apply(confint(cmod),FUN=exp)
apply(confint(cmod),FUN=exp,MARGIN=2)
?apply
confint(cmod)
exp(-.120179)
exp(.717)
exp(-.33265)
apply(confint(cmod),FUN=exp,MARGIN=2)[2,]
exp(cmod$coefficients[2]) ## because beta is the log odds ratio
dat<-data.frame("LogOdds"=logodds,"Odds"=odds,"Probability"=prob)
logodds<-x*cmod$coefficients[2] + cmod$coefficients[1]
odds<-exp(logodds)
prob<-odds/(odds+1)
dat<-data.frame("LogOdds"=logodds,"Odds"=odds,"Probability"=prob)
dat
dat
row.names(dat)<-NULL
dat
x<-50
logodds<-x*cmod$coefficients[2] + cmod$coefficients[1]
odds<-exp(logodds)
prob<-odds/(odds+1)
dat<-data.frame("LogOdds"=logodds,"Odds"=odds,"Probability"=prob)
row.names(dat)<-NULL
dat
x<-60
logodds<-x*cmod$coefficients[2] + cmod$coefficients[1]
odds<-exp(logodds)
prob<-odds/(odds+1)
dat<-data.frame("LogOdds"=logodds,"Odds"=odds,"Probability"=prob)
row.names(dat)<-NULL
dat
x<-31
logodds<-x*cmod$coefficients[2] + cmod$coefficients[1]
odds<-exp(logodds)
prob<-odds/(odds+1)
dat<-data.frame("LogOdds"=logodds,"Odds"=odds,"Probability"=prob)
row.names(dat)<-NULL
dat
x<-32
logodds<-x*cmod$coefficients[2] + cmod$coefficients[1]
odds<-exp(logodds)
prob<-odds/(odds+1)
dat<-data.frame("LogOdds"=logodds,"Odds"=odds,"Probability"=prob)
row.names(dat)<-NULL
dat
cmod <- glm(cbind(damage,6-damage)~temp,family=binomial,data=orings)
summary(cmod) #output omitted
cmod <- glm(cbind(damage,6-damage)~temp,family=binomial,data=orings)
# INPUT
# strata entered by columns
stratum1 <- c(31, 80, 93, 379)
stratum2 <- c(39, 149, 74, 465)
# 2-by-2 contingency tables for 2 strata
ovarian <- array(c(stratum1, stratum2), dim = c(2, 2, 2), dimnames = list(Pregnancies = c("None", "One or More"), Disease = c("Cancer", "No Cancer"), Stratum = c("Study 1", "Study 2")))
# TEST OF HOMOGENEITY: OR1 = OR2
# Step 1 - point estimates
OR1 <- (stratum1[1] * stratum1[4]) / (stratum1[3] * stratum1[2])
OR2 <- (stratum2[1] * stratum2[4]) / (stratum2[3] * stratum2[2])
lnOR1 <- log(OR1)
lnOR2 <- log(OR2)
# Step 2 - weights
w1 <- 1 / (1/stratum1[1] + 1/stratum1[2] + 1/stratum1[3] + 1/stratum1[4])
w2 <- 1 / (1/stratum2[1] + 1/stratum2[2] + 1/stratum2[3] + 1/stratum2[4])
# Step 3 - weighted mean of ln(OR1) and ln(OR2)
L <- (w1 * lnOR1 + w2 * lnOR2) / (w1 + w2)
# Step 4 - Chi-squared score
test.stat <- w1 * (lnOR1 - L)^2 + w2 * (lnOR2 - L)^2
# Step 5 - p-value
p.value <- pchisq(test.stat, df = 1, lower.tail = FALSE)
# OUTPUT
ovarian
c(OR1, OR2)
c(lnOR1,lnOR2)
c(w1, w2)
L
test.stat
p.value
# Note: If p.value > .05, then strata can be combined; proceed.
# TEST OF ASSOCIATION: ORsummary = 1
mantelhaen.test(ovarian, correct = FALSE)
# INPUT
# strata entered by columns
stratum1 <- c(31, 80, 93, 379)
stratum2 <- c(39, 149, 74, 465)
# 2-by-2 contingency tables for 2 strata
ovarian <- array(c(stratum1, stratum2), dim = c(2, 2, 2), dimnames = list(Pregnancies = c("None", "One or More"), Disease = c("Cancer", "No Cancer"), Stratum = c("Study 1", "Study 2")))
# TEST OF HOMOGENEITY: OR1 = OR2
# Step 1 - point estimates
OR1 <- (stratum1[1] * stratum1[4]) / (stratum1[3] * stratum1[2])
OR2 <- (stratum2[1] * stratum2[4]) / (stratum2[3] * stratum2[2])
lnOR1 <- log(OR1)
lnOR2 <- log(OR2)
# Step 2 - weights
w1 <- 1 / (1/stratum1[1] + 1/stratum1[2] + 1/stratum1[3] + 1/stratum1[4])
w2 <- 1 / (1/stratum2[1] + 1/stratum2[2] + 1/stratum2[3] + 1/stratum2[4])
# Step 3 - weighted mean of ln(OR1) and ln(OR2)
L <- (w1 * lnOR1 + w2 * lnOR2) / (w1 + w2)
# Step 4 - Chi-squared score
test.stat <- w1 * (lnOR1 - L)^2 + w2 * (lnOR2 - L)^2
# Step 5 - p-value
p.value <- pchisq(test.stat, df = 1, lower.tail = FALSE)
# OUTPUT
ovarian
c(OR1, OR2)
c(lnOR1,lnOR2)
c(w1, w2)
L
test.stat
p.value
# Note: If p.value > .05, then strata can be combined; proceed.
# TEST OF ASSOCIATION: ORsummary = 1
mantelhaen.test(ovarian, correct = FALSE)
stratum1 <- c(31, 80, 93, 379)
stratum2 <- c(39, 149, 74, 465)
# 2-by-2 contingency tables for 2 strata
ovarian <- array(c(stratum1, stratum2), dim = c(2, 2, 2), dimnames = list(Pregnancies = c("None", "One or More"), Disease = c("Cancer", "No Cancer"), Stratum = c("Study 1", "Study 2")))
ovarian
# TEST OF HOMOGENEITY: OR1 = OR2
# Step 1 - point estimates
OR1 <- (stratum1[1] * stratum1[4]) / (stratum1[3] * stratum1[2])
OR1
OR2 <- (stratum2[1] * stratum2[4]) / (stratum2[3] * stratum2[2])
OR2
lnOR1 <- log(OR1)
lnOR2 <- log(OR2)
# Step 2 - weights
w1 <- 1 / (1/stratum1[1] + 1/stratum1[2] + 1/stratum1[3] + 1/stratum1[4])
w2 <- 1 / (1/stratum2[1] + 1/stratum2[2] + 1/stratum2[3] + 1/stratum2[4])
# Step 3 - weighted mean of ln(OR1) and ln(OR2)
L <- (w1 * lnOR1 + w2 * lnOR2) / (w1 + w2)
# Step 4 - Chi-squared score
test.stat <- w1 * (lnOR1 - L)^2 + w2 * (lnOR2 - L)^2
# Step 5 - p-value
p.value <- pchisq(test.stat, df = 1, lower.tail = FALSE)
p.value
# OUTPUT
ovarian
c(OR1, OR2)
c(lnOR1,lnOR2)
c(w1, w2)
L
lnOR1 <- log(OR1)
test.stat
p.value
mantelhaen.test(ovarian, correct = FALSE)
mat1<-c(416,419,365)
chisq.test(mat1)
mat2<-rbind(c(200,190,210),c(216,229,155))
chisq.test(mat2)
prop.test(c(24,22),c(2772,2772))
prop.test(c(24,22),c(2772,2772),correct = FALSE)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
vowel.train$y<-as.factor(vowe.train$y)
set.seed(33833)
vowel.test$y<-as.factor(vowel.test$y)
vowel.train$y<-as.factor(vowel.train$y)
set.seed(33833)
library(AppliedPredictiveModeling)
library(caret)
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
vowel.train$y<-as.factor(vowel.train$y)
set.seed(33833)
rffit<-train(y~.,data = vowel.train,method = 'rf')
gbfit<-train(y~.,data=vowel.train,method='gbm')
predict(rffit,vowel.test)
confusionMatrix(vowel.test,predict(rffit,vowel.test))
confusionMatrix(vowel.test$y,predict(rffit,vowel.test))
confusionMatrix(vowel.test$y,predict(gbfit,vowel.test))
vowel.test$y == predict(rffit,vowel.test)
vowel.test[vowel.test$y == predict(rffit,vowel.test)]
vowel.test[vowel.test$y == predict(rffit,vowel.test),]
rfright<-vowel.test[vowel.test$y == predict(rffit,vowel.test),]
gbright<-vowel.test[vowel.test$y == predict(gbfit,vowel.test),]
gbright
gbright<-which(vowel.test$y == predict(gbfit,vowel.test))
rfright<-which(vowel.test$y == predict(rffit,vowel.test))
rfright
gbright
choose(980,437)
choose(980,437)/980
?choose
5!
dens<- function(y, th){
dens0<-NULL
for (i in 1:length(th))
dens0<-c(dens0,prod(dcauchy(y,th[i],1)))
dens0
}
y<- c(-2,-1,0,1.5,2.5)
step <- 0.1
theta <- seq(step/2, 1-step/2,step)
theta
dens.unnorm<-dens(y,theta)
dens.unnorm
?prod
dens.norm <- dens.unnorm/(step*sum(dens.unnorm))
plot(theta,dens.norm,ylim=c(0,1.1*max(dens.norm)),type='l',
xlab='theta', ylab='normalized density', xaxs='i', yaxs='i', cex=2)
theta <- rgamma(1000,238)/10
hist(theta)
y1986<- rpois(1000,theta)
print(sort(y1986)[c(25,976)])
invF<- function(x){
(.5*log(x))^(1/3)
}
compute_random <- function(n){
rvs <- runif(25)
rvs <- invF(rvs)
return rvs
}
invF<- function(x){
(.5*log(x))^(1/3)
}
invF(5)
F<-function(x){exp(-2*x**3)}
F(.9301395)
invF<- function(x){
(-.5*log(1-x))^(1/3)
}
F<-function(x){6*x^2exp(-2*x**3)}
F<-function(x){6*x^2*exp(-2*x**3)}
F<-function(x){exp(-2*x**3)}
F(5)
F(1)
invF(0.1353353)
invF(1)
invF(0)
F(0)
library("Rcmdr")
library("Rcmdr")
library("Rcmdr")
(4+3) * 7
x<-c("BP1 dst", "STGELSE","BP13 df")
x
gsub("BP"*,"BP",x)
gsub("BP*","BP",x)
gsub(pattern = "BP*",replacement = "BP",x = c("BP dfajskdfj"))
sub(pattern = "BP*",replacement = "BP",x = c("BP dfajskdfj"))
sub(pattern = "BP*",replacement = "BP",x = c("BP dfajskdfj"))
x <- c("This is a sentence about axis","A second pattern is also listed here")
sub("is", "XY", x)
y<- c(65,156,100,134,16,108,121,4,39,143,56,26,22,1,1,5,65)
x<- c(3.36,2.88,3.63,3.41,3.78,4.02,4.00,4.23,3.73,3.85,3.97,4.51,4.54,5.00,5.00,4.72,5.00)
len(x)
length(x)
length(y)
df = cbind(x,y)
df
library("ggplot2")
qplot(x=x,y=y,data=df)
data.frame(df)
df< - data.frame(df)
z<-(14-5)/.5
z
z<-(14-15)/.5
x.1 <- rbinom(n = 100,prob = .5,size=1000)
x.1 <- rbinom(n = 100,prob = .5,size=1000)
x.2 <- rnorm(mu=0,sigma=1,size=1000)
x.3 <- rexp(n=1000,rate = 2)
x.4 <- rpois(n = 1000,lambda=4)
x.2 <- rnorm(mean=0,sd=1,size=1000)
x.2 <- rnorm(mean=0,sd=1,n=1000)
x.1 <- rbinom(n = 100,prob = .5,size=1000)
x.2 <- rnorm(mean=0,sd=1,n=1000)
x.3 <- rexp(n=1000,rate = 2)
x.4 <- rpois(n = 1000,lambda=4)
plot(x.1)
hist(x.1)
x.1 <- rbinom(n = 100,prob = .3,size=1000)
x.2 <- rnorm(mean=0,sd=1,n=1000)
x.3 <- rexp(n=1000,rate = 2)
x.4 <- rpois(n = 1000,lambda=4)
par(mfrow = (2,2))
par(mfrow = 2,col = 2)
par(mfrow = 2)
hist(x.1)
hist(x.2)
hist(x.3)
hist(x.4)
library("Rcmdr")
data(AirPassengers)
attach(AirPassengers)
data(Titanic)
view(Titanic)
View(Titanic)
Titanic
library('sqldf')
sqldf("SELECT * FROM Titanic;")
set.seed(43657)
n <- 100
x1 <- rnorm(n)
x2 <- 0.5*x1+rnorm(n)
xb <- x1-x2
pr <- exp(xb)/(1 + exp(xb))
y <- 1*(runif(n <pr))
mydata <- data.frame(y,x1,x2)
mydata
mod <- glm(y~x1+x2, data=mydata, family=binomial)
mod
fitted(mod)
hl<-hoslem.test(mod$y,fitted(mod),g=10)
library(ResourceSelection)
hl<-hoslem.test(mod$y,fitted(mod),g=10)
cbind(hl$expected,hl$observed)
meanprobs <- array(0, dim=c(10,2))
expevents <- array(0,dim=c(10,2))
obsevents <- array(0, dim=c(10,2))
for (i in 1:10) {
meanprobs[i,1] <- mean(pihat[pihatcat==i])
expevents[i,1] <- sum(pihatcat==i)*meanprobs[i,1]
obsevents[i,1] <- sum(y[pihatcat==i])
meanprobs[i,2] <- mean(1-pihat[pihatcat==i])
expevents[i,2] <- sum(pihatcat==i)*meanprobs[i,2]
obsevents[i,2] <- sum(1-y[pihatcat==i])
}
pihatcat <- cut(pihat, breaks=c(0,quantile(pihat, probs=seq(0.1,0.9m0.1)) ,1), labels=FALSE)
pihatcat <- cut(pihat, breaks=c(0,quantile(pihat, probs=seq(0.1,0.9, 0.1)) ,1), labels=FALSE)
pihat <- mod$fitted
pihatcat <- cut(pihat, breaks=c(0,quantile(pihat, probs=seq(0.1,0.9, 0.1)) ,1), labels=FALSE)
meanprobs <- array(0, dim=c(10,2))
expevents <- array(0,dim=c(10,2))
obsevents <- array(0, dim=c(10,2))
for (i in 1:10) {
meanprobs[i,1] <- mean(pihat[pihatcat==i])
expevents[i,1] <- sum(pihatcat==i)*meanprobs[i,1]
obsevents[i,1] <- sum(y[pihatcat==i])
meanprobs[i,2] <- mean(1-pihat[pihatcat==i])
expevents[i,2] <- sum(pihatcat==i)*meanprobs[i,2]
obsevents[i,2] <- sum(1-y[pihatcat==i])
}
meanprobs
hosmerlemeshow <- sum((obsevents-expevents)^2 / expevents)
hosmerlemeshow
set.seed(43657)
n <- 100
x1 <- rnorm(n)
x2 <- 0.5*x1+rnorm(n)
xb <- x1-x2
pr <- exp(xb)/(1 + exp(xb))
y <- 1*(runif(n <pr))
mydata <- data.frame(y,x1,x2)
mod <- glm(y~x1+x2, data=mydata, family=binomial)
library(ResourceSelection)
hl<-hoslem.test(mod$y,fitted(mod),g=10)
cbind(hl$expected,hl$observed)
pihat <- mod$fitted
pihatcat <- cut(pihat, breaks=c(0,quantile(pihat, probs=seq(0.1,0.9, 0.1)) ,1), labels=FALSE)
meanprobs <- array(0, dim=c(10,2))
expevents <- array(0,dim=c(10,2))
obsevents <- array(0, dim=c(10,2))
for (i in 1:10) {
meanprobs[i,1] <- mean(pihat[pihatcat==i])
expevents[i,1] <- sum(pihatcat==i)*meanprobs[i,1]
obsevents[i,1] <- sum(y[pihatcat==i])
meanprobs[i,2] <- mean(1-pihat[pihatcat==i])
expevents[i,2] <- sum(pihatcat==i)*meanprobs[i,2]
obsevents[i,2] <- sum(1-y[pihatcat==i])
}
hosmerlemeshow <- sum((obsevents-expevents)^2 / expevents)
hosmerlemeshow
sum(obsevents - expevents)^2
hl
set.seed(43657)
n <- 100
x1 <- rnorm(n)
x2 <- 0.5*x1+rnorm(n)
xb <- x1-x2
pr <- exp(xb)/(1 + exp(xb))
y <- 1*(runif(n <pr))
mydata <- data.frame(y,x1,x2)
mod <- glm(y~x1+x2, data=mydata, family=binomial)
library(ResourceSelection)
mod <- glm(y~x, data=mydata, family=binomial)
set.seed(43657)
n <- 100
x <- rnorm(n)
mod <- glm(y~x, data=mydata, family=binomial)
library(ResourceSelection)
hl<-hoslem.test(mod$y,fitted(mod),g=10)
hl
install.packages("truncshow")
setwd("~/Google Drive/Academic/UM-Biostatistics/SS_16/EECS 545/bayesofthrones/support_code/original_R/model_12_scripts")
set.seed(280814)
source("got_readin.R")
source("fit_model12.R")
source("simulate_model12.R")
source("plotting_for_model12.R")
source("inference_test_model12.R")
